# -*- coding: utf-8 -*-
"""Proyek MetStat.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1whGLwSmUvvAQ-YWK_epgD_epMXJ6rhXd

## **Kelompok 7** ----- **Project UAS Metode Statistika Semester Genap**
- Sri Ranita ------------------ (003)
- Dimyadi Suhartono --- (014)
- Salsabila Alya ----------- (048)
- Ferdiansyah Juliputra (057)
- Dhia Alif Azhar ---------- (079)

## **Import Packages**
Import packages and classes yang dibutuhkan untuk multiple linear regression.
"""

import io
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from google.colab import files

"""## **Load Screen on Time Datasets**"""

# Loading datasetsn
dataset = pd.read_csv('screentime-3.csv')
print(dataset)

"""## **Screen on Time Datasets**

Dataset ini berisikan  83 observasi dengan 4 variabel. Tujuan dari analisis ini adalah untuk mengetahui apakah gender, jumlah sosial media, dan kapasitas baterai berpengaruh terhadap jumlah durasi screen on time mahasiswa TSD 21 Unair. Variabel prediktor itu sendiri adalah Gender(X1), Sosmed(X2), dan Baterai(X3) sedangkan  variabel responnya adalah Screen(Y).
"""

# Menampilkan 5 baris pertama dari dataset
dataset.head()

# Isi variabel dari dataset
print(dataset.keys())

"""## **Data Preprocessing**"""

# Memeriksa apakah ada missing value
dataset.isnull().sum()
dataset.info()

"""### Membuat Variabel Dummy"""

dum_gender = pd.get_dummies(dataset['Gender'], drop_first = True) #true untuk menghilangkan yang lain maksudnya biar kodenya tinggal satu
dum_game = pd.get_dummies(dataset['Main Game/Tidak Main'], drop_first = True)
dum_inex = pd.get_dummies(dataset['Introvert/Ekstrovert'], drop_first = True)

df = pd.DataFrame(dataset)

# Using 'dum_book' as the column name
df = df.assign(dum_gender = dum_gender)
df = df.assign(play_game = dum_game)
df = df.assign(is_inex = dum_inex)
df2 = df.dropna()
# Observe the result
df2

"""### Menambahkan Kolom Variabel Dummy ke dalam DataFrame dari Dataset"""

df = pd.DataFrame(dataset)

# Using 'dum_smoker' as the column name
df1 = df.assign(dum_gender = dummy_gender)
df2 = df1.assign(dummy_game = dummy_game)
df3 = df2.assign(dum_inex = dummy_inex)

   
# Observe the result
df3

"""### Menghapus Kolom Variabel Gender"""

# Examine the shape of the DataFrame
print(data2.shape)

# Drop the 'Gender' column
data2.drop(['Gender'], axis='columns', inplace=True)

# Examine the shape of the DataFrame (again)
print(data2.shape)

# DataFrame after removing the 'Gender' column
data2.head()

"""## **Parameter Regresi**"""

x = data2[['Sosmed', 'Baterai', 'dum_gender']]
y = data2['Screen']

# Summary
X = (sm.add_constant(x))
hasil = sm.OLS(y, X.astype(float)).fit()
print(hasil.summary())

"""### Persamaan Regresi

$\hat{Y} = 609.412 + 19.87 X_1 - 0.0347 X_2$ - 21.89 X3 + 57.52 X4 - 42.086 X5 - 69.48 X6

ATAU

Y = 609.412 + 19.87 Sosmed - 0.0347 Baterai - 21.89 Tidur + 57.52 Gender - 42.086 Game - 69.48 Introvert/Ekstrovert

## **Uji Signifikansi Parameter**

### **Uji Serentak**
$H_{0}: \beta_{1} = \beta_{2} = \beta_{3} = 0$

$H_{1}$: minimal ada satu $\beta_{i}  \neq 0$, $i=1,2$
"""

print('F-hitung\t= ', hasil.fvalue) # F-hitung
print('P-value\t\t= ', hasil.f_pvalue) # P-value

alpha = 0.35 #Supaya bisa Tolak H0, taraf signifikansi nya baru bisa dari 0,35 (65%)

#Daerah penolakan dan keputusan
if hasil.f_pvalue > alpha:
	print('Gagal Tolak H0 artinya tidak ada relasi linier antara Y (charges) dan X')
else:
	print('Tolak H0 sehingga terdapat relasi linier antara Y (charges) dan X')

"""Sehingga dapat disimpulkan bahwa variabel sosmed, baterai,  dan gender (ketika digabungkan) tidak berpengaruh terhadap jumlah screen time tiap mahasiswa.

### **Uji Parsial**
Untuk  𝛽1  -------------------- Untuk  𝛽2 ------------------ Untuk  𝛽3 

𝐻0 : 𝛽1 = 0  --------------- 𝐻0 : 𝛽2 = 0 --------------- 𝐻0 : 𝛽3 = 0 

𝐻1 : 𝛽1 ≠ 0  --------------- 𝐻1 : 𝛽2 ≠ 0 --------------- 𝐻1 : 𝛽3 ≠ 0
"""

print('t-hitung =', hasil.tvalues) # t-hitung
print()
print('P-value =', hasil.pvalues) # P-value

"""Alpha = 0.35

Dikarenakan p-value 2 dari 3 parameter lebih kecil dari alpha (0.35), maka dapat diputuskan Gagal Tolak H0, yang berarti variabel prediktor sosmed dan baterai tidak berpengaruh secara signifikan terhadap variabel respons. Sedangkan variabel gender memiliki pengaruh terhadap variabel respon. 
Maka, dapat disimpulkan bahwa tidak terdapat relasi linier antara Y (Screen) dengan X1 (Sosmed) , Y (Screen) dengan X2 (Baterai), tetapi terdapat relasi linear antara Y (Screen) dengan X3 (Gender).

## **Nilai Koefisien Determinasi (R-Squared) dan Adjusted R-Squared**
"""

print('R2 \t\t= ', hasil.rsquared)
print('Adjusted R2 \t= ', hasil.rsquared_adj)

"""Nilai 𝑅2 dan adjusted 𝑅2 lebih kecil apabila dibandingkan 𝑅2 pada model regresi linier yang memodelkan Y (Screen) dengan X (Sosmed, Baterai, Gender).

## **Pengujian Asumsi**

### Linieritas antara Y (Screen) dan X (Sosmed, Baterai, Gender)
"""

plt.figure(figsize=(30, 10))

predictors = ['Sosmed', 'Baterai', 'dum_gender']
response = data2['Screen']

for i, col in enumerate(predictors):
    plt.subplot(1, len(predictors) , i+1)
    x = data2[col]
    y = response
    plt.scatter(x, y, marker='o', color='darkblue')
    plt.title(col)
    plt.xlabel(col)
    plt.ylabel('Screen')

"""Berdasarkan plot diatas, terlihat bahwa : 

...

### Multikolinieritas pada Variabel Independen
"""

from patsy import dmatrices
from statsmodels.stats.outliers_influence import variance_inflation_factor

vif_x = data2[["Sosmed", "Baterai", "dum_gender"]]

# VIF dataframe
vif_data = pd.DataFrame()
vif_data["feature"] = vif_x.columns
  
# calculating VIF for each feature
vif_data["VIF"] = [variance_inflation_factor(vif_x.values, i)
                          for i in range(len(vif_x.columns))]
  
print(vif_data)

"""Didapatkan VIF kedua variabel independen > 10, maka dapat disimpulkan tidak ada kasus multikolinieritas antar variabel independen.


Note:

Apabila di kasus lain terjadi multikolinieritas pada variabel independennya, maka langkah yang dapat dilakukan adalah mengganti atau menghapus variabel yang memiliki VIF tinggi, dan/atau menambah jumlah observasi.

### Autokorelasi pada residual
"""

# residuals model regresi linier berganda
residual = hasil.resid

# membuat plot residuals vs time order

# membuat list time order
time1 = list(range(1,83+1))
print(time1)

plt.scatter(x=time1, y=residual)
plt.xlabel('time order', fontsize=12)
plt.ylabel('residuals', fontsize=12)
plt.show()

"""Berdasarkan plot diatas, dapat disimpulkan bahwa titik-titik membentuk ... . Sehingga dapat disimpulkan bahwa tidak / ada abnormal atau kelainan yang terdapat di plot tersebut.

### Heterokedastisitas pada Residual
"""

# membuat plot residuals vs fitted value

plt.scatter(x=hasil.fittedvalues, y=residual)
plt.xlabel('fitted value', fontsize=12)
plt.ylabel('residuals', fontsize=12)
plt.show()

"""Terlihat pada grafik scatter di atas, bahwa terdapat ... . Maka, dapat disimpulkan bahwa tidak ada / terdapat gejala heteroskedastisitas pada data.

Dengan demikian, untuk membuktikannya lebih lanjut diperlukan uji heteroskedasitisitas yang lebih lanjut, seperti Uji Glejser, Uji Park, dan Uji Spearman.

### Normalitas untuk Error
"""

from scipy.stats import kstest

# uji normalitas dengan kolmogorov-smirnov test
ks1=kstest(residual,'norm')
print('Statistic KS\t:', ks1.statistic.round(4))
print('P-value\t\t:', ks1.pvalue.round(4))

# interpret
alpha = 0.05
if ks1.pvalue > alpha:
	print('Data Berdistribusi Normal (Gagal Tolak H0)')
else:
	print('Data Tidak Berdistribusi Normal (Tolak H0)')

"""## Memilih variabel dengan forward selection, backward elimination, atau stepwise regression untuk mendapat model regresi akhir"""

from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt 
from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs

screentime = data2
screen = pd.DataFrame(data2, columns = data2.feature_names)
screen['Screen'] = screentime.target
X = screen.drop('Screen', 1)
y = screen['Screen']
lr = LinearRegression()
sfs = plot_sfs(lr,
          k_features=13,
          forward=True,
          scoring ='neg_mean_squared_error',
          cv=5)

sfs = sfs.fit(x,y)
fig = plot_sfs(sfs.get_metric_dict(), kind='std_err')
print('Selected Features :', sfs.k_feature_names_)
print('Selected Features ID :', sfs.k_feature_idx_)
plt.title('Sequential Forward Selection (w.StdErr)')
plt.grid()
plt.show()